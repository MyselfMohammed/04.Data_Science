{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb5fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "\n",
    "import pickle\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae38080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>12300.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12400.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         bp sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  2.0  76.459948  c  3.0  0.0  normal  abnormal  notpresent  notpresent   \n",
       "1  3.0  76.459948  c  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "2  4.0  76.459948  a  1.0  0.0  normal    normal  notpresent  notpresent   \n",
       "3  5.0  76.459948  d  1.0  0.0  normal    normal  notpresent  notpresent   \n",
       "4  5.0  50.000000  c  0.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "          bgr  ...        pcv            wc        rc  htn  dm  cad  appet  \\\n",
       "0  148.112676  ...  38.868902   8408.191126  4.705597   no  no   no    yes   \n",
       "1  148.112676  ...  34.000000  12300.000000  4.705597   no  no   no    yes   \n",
       "2   99.000000  ...  34.000000   8408.191126  4.705597   no  no   no    yes   \n",
       "3  148.112676  ...  38.868902   8408.191126  4.705597   no  no   no    yes   \n",
       "4  148.112676  ...  36.000000  12400.000000  4.705597   no  no   no    yes   \n",
       "\n",
       "     pe  ane classification  \n",
       "0   yes   no            yes  \n",
       "1  poor   no            yes  \n",
       "2  poor   no            yes  \n",
       "3  poor  yes            yes  \n",
       "4  poor   no            yes  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Loading Original Dataset : \n",
    "dataset=pd.read_csv(\"Pre-processed_CKD_Data.csv\",index_col=None)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bf3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>classification_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>57.482105</td>\n",
       "      <td>3.077356</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>12.518156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         bp   al   su         bgr         bu        sc         sod  \\\n",
       "0  2.0  76.459948  3.0  0.0  148.112676  57.482105  3.077356  137.528754   \n",
       "1  3.0  76.459948  2.0  0.0  148.112676  22.000000  0.700000  137.528754   \n",
       "2  4.0  76.459948  1.0  0.0   99.000000  23.000000  0.600000  138.000000   \n",
       "3  5.0  76.459948  1.0  0.0  148.112676  16.000000  0.700000  138.000000   \n",
       "4  5.0  50.000000  0.0  0.0  148.112676  25.000000  0.600000  137.528754   \n",
       "\n",
       "        pot       hrmo  ...  pc_normal  pcc_present  ba_present  htn_yes  \\\n",
       "0  4.627244  12.518156  ...          0            0           0        0   \n",
       "1  4.627244  10.700000  ...          1            0           0        0   \n",
       "2  4.400000  12.000000  ...          1            0           0        0   \n",
       "3  3.200000   8.100000  ...          1            0           0        0   \n",
       "4  4.627244  11.800000  ...          1            0           0        0   \n",
       "\n",
       "   dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  classification_yes  \n",
       "0       0        0          1       1        0                   1  \n",
       "1       0        0          1       0        0                   1  \n",
       "2       0        0          1       0        0                   1  \n",
       "3       0        0          1       0        1                   1  \n",
       "4       0        0          1       0        0                   1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Duplicating the Original Dataset\n",
    "dataset2 = dataset\n",
    "\n",
    "#3.Classifying the Nominal Columns in Dataset : \n",
    "dataset2 = pd.get_dummies(dataset2, drop_first=True)\n",
    "print(dataset2.shape)\n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce24589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 27)\n",
      "(399,)\n"
     ]
    }
   ],
   "source": [
    "#4.Assigning Variables (Independent/Dependent) : \n",
    "\n",
    "indep_X = dataset2.drop('classification_yes', 1)\n",
    "print(indep_X.shape)\n",
    "\n",
    "dep_Y = dataset2['classification_yes']\n",
    "print(dep_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ef8273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear', random_state=0)\n",
      "SVC(random_state=0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "when `importance_getter=='auto'`, the underlying estimator SVC should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20484\\1682310706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mRFE_List\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mRFE_List\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE_Features_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindep_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdep_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mConfusion_Matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20484\\1682310706.py\u001b[0m in \u001b[0;36mRFE_Features_Classification\u001b[1;34m(indep_X, dep_Y, n)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m#logistic_RFE = RFE(i, n)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mlogistic_RFE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mlogistic_RFE_Fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_RFE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindep_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdep_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mlogistic_RFE_Feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_RFE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindep_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mRFE_List\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogistic_RFE_Feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    287\u001b[0m                 \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimportance_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                 \u001b[0mtransform_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"square\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             )\n\u001b[0;32m    291\u001b[0m             \u001b[0mranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\feature_selection\\_base.py\u001b[0m in \u001b[0;36m_get_feature_importances\u001b[1;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 205\u001b[1;33m                     \u001b[1;34m\"when `importance_getter=='auto'`, the underlying \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m                     \u001b[1;34mf\"estimator {estimator.__class__.__name__} should have \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[1;34m\"`coef_` or `feature_importances_` attribute. Either \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator SVC should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
     ]
    }
   ],
   "source": [
    "# Creating Function(s) :\n",
    "\n",
    "def train_test_split_and_StandardScaler(indep_X,dep_Y):\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def RFE_Features_Classification(indep_X, dep_Y, n):\n",
    "   \n",
    "    RFE_List = []\n",
    "\n",
    "    #logistic_Regression = LogisticRegression(solver='lbfgs')\n",
    "    logistic_Regression = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "    svc_Linear = SVC(kernel = 'linear', random_state = 0)\n",
    "    svc_NonLinear = SVC(kernel = 'rbf', random_state = 0)\n",
    "    gaussianNB = GaussianNB()\n",
    "    kNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    decisionTree = DecisionTreeClassifier(criterion = 'gini',max_features = 'sqrt',splitter = 'best', random_state = 0)\n",
    "    randomForest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        \n",
    "    RFE_Model_List = [logistic_Regression, svc_Linear, svc_NonLinear, gaussianNB, kNN, decisionTree, randomForest]\n",
    "\n",
    "    for model in RFE_Model_List:\n",
    "        print(model)\n",
    "        #logistic_RFE = RFE(i, n)\n",
    "        logistic_RFE = RFE(estimator = model, n_features_to_select=n)\n",
    "        logistic_RFE_Fit = logistic_RFE.fit(indep_X, dep_Y)\n",
    "        logistic_RFE_Feature = logistic_RFE.transform(indep_X)\n",
    "        RFE_List.append(logistic_RFE_Feature)\n",
    "    return RFE_List\n",
    "\n",
    "RFE_List = RFE_Features_Classification(indep_X, dep_Y, 6)\n",
    "\n",
    "def Confusion_Matrix(classifier, X_test, Y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    ConfusionMatrix = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "    from sklearn.metrics import classification_report \n",
    "    ClassificationReport = classification_report(Y_test, y_pred)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    AccuracyScore=accuracy_score(Y_test, y_pred)         \n",
    "\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore \n",
    "\n",
    "def Logistic_Regression(X_train,Y_train,X_test):       \n",
    "    # Fitting K-NN to the Training set\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    #classifier = LogisticRegression(random_state = 0) \n",
    "    classifier = LogisticRegression(solver='lbfgs', max_iter= 5000)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore   \n",
    "\n",
    "def SVM_Linear(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def SVM_Non_Linear(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def Naive_Bayes(X_train,Y_train,X_test):       \n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def KNN(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def DecisionTree(X_train,Y_train,X_test):\n",
    "\n",
    "    # Fitting K-NN to the Training set\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def RandomForest(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "\n",
    "def RFE_Classification(accuracy_LogisticRegression, accuracy_SVM_Linear, accuracy_SVM_NonLinear, \n",
    "                           accuracy_KNN, accuracy_NaiveBayes, accuracy_DecisionTree, accuracy_RandomForest): \n",
    "\n",
    "    dataframe=pd.DataFrame(index=['Logistic Regression', 'SVC', 'Decision Tree', 'Random Forest'],\n",
    "                           columns=['Logistic Regression','SVM Linear','SVM Non Linear','KNN','Naive Bayes',\n",
    "                                    'Decision Tree','Random Forest'])\n",
    "    \n",
    "    #Function - enumerate() acts as a Counter which Iterates index starting from 0 (by default) and their item(s) from the iterable\n",
    "    #Use enumerate() when We need both Position in the loop (number) and its value from the iterable (idex)\n",
    "    \n",
    "    for indexCount,indexValue in enumerate(dataframe.index):      \n",
    "        dataframe['Logistic Regression'][indexValue]=accuracy_LogisticRegression[indexCount]       \n",
    "        dataframe['SVM Linear'][indexValue]=accuracy_SVM_Linear[indexCount]\n",
    "        dataframe['SVM Non Linear'][indexValue]=accuracy_SVM_NonLinear[indexCount]\n",
    "        dataframe['KNN'][indexValue]=accuracy_KNN[indexCount]\n",
    "        dataframe['Naive Bayes'][indexValue]=accuracy_NaiveBayes[indexCount]\n",
    "        dataframe['Decision Tree'][indexValue]=accuracy_DecisionTree[indexCount]\n",
    "        dataframe['Random Forest'][indexValue]=accuracy_RandomForest[indexCount]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty Lists\n",
    "accuracy_LogisticRegression = []\n",
    "accuracy_SVM_Linear = []\n",
    "accuracy_SVM_NonLinear = []\n",
    "accuracy_KNN = []\n",
    "accuracy_NaiveBayes = []\n",
    "accuracy_DecisionTree = []\n",
    "accuracy_RandomForest = []\n",
    "\n",
    "for i in RFE_List:\n",
    "    \n",
    "    #6.Calling a Created Function - train_test_split_and_StandardScaler: which returns - X_train, X_test, Y_train, Y_test\n",
    "    #Hence, Passing (i, dep_Y) along with Selected Number of Features instead of K_Best (k_Best, dep_Y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split_and_StandardScaler(i, dep_Y)   \n",
    "\n",
    "    #Creating Various Models as follows :\n",
    "\n",
    "    #7.Calling a Created Function - LogisticRegression(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = LogisticRegression(X_train,Y_train,X_test)\n",
    "    accuracy_LogisticRegression.append(accuracy_score)\n",
    "\n",
    "    #8.Calling a Created Function - SVM_Linear(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = SVM_Linear(X_train,Y_train,X_test)  \n",
    "    accuracy_SVM_Linear.append(accuracy_score)\n",
    "\n",
    "    #9.Calling a Created Function - SVM_Non_Linear(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = SVM_Non_Linear(X_train,Y_train,X_test)  \n",
    "    accuracy_SVM_NonLinear.append(accuracy_score)\n",
    "\n",
    "    #10.Calling a Created Function - KNN(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = KNN(X_train,Y_train,X_test)  \n",
    "    accuracy_KNN.append(accuracy_score)\n",
    "\n",
    "    #11.Calling a Created Function - Naive_Bayes(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Naive_Bayes(X_train,Y_train,X_test)  \n",
    "    accuracy_NaiveBayes.append(accuracy_score)\n",
    "\n",
    "    #12.Calling a Created Function - DecisionTree(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = DecisionTree(X_train,Y_train,X_test)  \n",
    "    accuracy_DecisionTree.append(accuracy_score)\n",
    "\n",
    "    #13.Calling a Created Function - RandomForest(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = RandomForest(X_train,Y_train,X_test)  \n",
    "    accuracy_RandomForest.append(accuracy_score)\n",
    "\n",
    "#14.Calling a Created Function - RFE_Classification(With Below Parameters): which returns - dataframe    \n",
    "result=RFE_Classification(accuracy_LogisticRegression, accuracy_SVM_Linear, accuracy_SVM_NonLinear, \n",
    "                               accuracy_KNN, accuracy_NaiveBayes, accuracy_DecisionTree, accuracy_RandomForest)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 6 Features\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 5 Features\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 4 Features\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 3 Features\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 2 Features\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 1 Feature\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334bbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b05b77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
